{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison\n",
    "Authors: Yuanzhe Marco Ma, Arash Shamseddini, Kaicheng Tan, Zhenrui Yu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "- [General Overview](#1)\n",
    "- [Data preprocessing](#2)\n",
    "- [Models](#3) \n",
    "    - [Ridge](#3)\n",
    "    - [SVR](#4)\n",
    "    - [Random Forest](#5)\n",
    "- [Conclusion](#6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. General Overview <a class=\"anchor\" id=\"1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict the IMDB scores (ranging from 0 ~ 10), we decided to choose the best model from three sklearn (Pedregosa et al. 2011) candiatates, sklearn linear_model Ridge, sklearn SVR(RBF kernel) estimator, and sklearn ensemble RandomForestRegressor. The score we would like to use is $R^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import (\n",
    "    OrdinalEncoder,\n",
    "    StandardScaler,\n",
    ")\n",
    "from scipy.stats import loguniform\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Data preprocessing <a class=\"anchor\" id=\"2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['n_words']\n",
    "text_feature = 'Text'\n",
    "ordinal_features = ['sentiment']\n",
    "drop_features = ['Id', 'Author']\n",
    "target = 'Rating'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../Data/processed/train.csv\")\n",
    "X_train, y_train = train_df.drop(columns=[target] + drop_features), train_df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('text', CountVectorizer(max_features=20_000, max_df=0.6), text_feature),\n",
    "            ('num', StandardScaler(), numeric_features),\n",
    "            ('ord', OrdinalEncoder(categories=[['neg', 'compound', 'neu', 'pos']]), ordinal_features)\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III.Ridge <a class=\"anchor\" id=\"3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   44.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('prepro',\n",
       "                                        ColumnTransformer(transformers=[('text',\n",
       "                                                                         CountVectorizer(max_df=0.6,\n",
       "                                                                                         max_features=20000),\n",
       "                                                                         'Text'),\n",
       "                                                                        ('num',\n",
       "                                                                         StandardScaler(),\n",
       "                                                                         ['n_words']),\n",
       "                                                                        ('ord',\n",
       "                                                                         OrdinalEncoder(categories=[['neg',\n",
       "                                                                                                     'compound',\n",
       "                                                                                                     'neu',\n",
       "                                                                                                     'pos']]),\n",
       "                                                                         ['sentiment'])])),\n",
       "                                       ('Ridge', Ridge())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'Ridge__alpha': array([ 800,  850,  900,  950, 1000, 1050, 1100, 1150])},\n",
       "             scoring='r2', verbose=1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_pipe = Pipeline(\n",
    "        steps=[\n",
    "            (\"prepro\", preprocessor),\n",
    "            (\"Ridge\", Ridge())\n",
    "        ]\n",
    "    )\n",
    "param_grid = {\n",
    "        'Ridge__alpha': np.arange(800, 1200, 50)\n",
    "    }\n",
    "hyper_parameters_search = GridSearchCV(ridge_pipe, param_grid=param_grid, n_jobs=-1, scoring='r2', verbose=1)\n",
    "hyper_parameters_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>2.198422</td>\n",
       "      <td>0.511951</td>\n",
       "      <td>0.53279</td>\n",
       "      <td>0.799778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fit_time  score_time  test_score  train_score\n",
       "Ridge  2.198422    0.511951     0.53279     0.799778"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = {}\n",
    "scores = cross_validate(\n",
    "    hyper_parameters_search.best_estimator_,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    scoring='r2',\n",
    "    return_train_score=True)\n",
    "\n",
    "df = pd.DataFrame(scores)\n",
    "results_df[\"Ridge\"] = df.mean()\n",
    "pd.DataFrame(results_df).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tuned the Alpha hyperparameter of Ridge using sklearn's [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html). The Alpha hyperparameter controls the complexity of our model. We want to pick the best Alpha so that our model does a decent job in predicting while avoiding over-fitting. Based on the tuning, we found that when alpha=800, we could get the best result. The result is shown above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV.SVR <a class=\"anchor\" id=\"3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed: 12.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('prepro',\n",
       "                                        ColumnTransformer(transformers=[('text',\n",
       "                                                                         CountVectorizer(max_df=0.6,\n",
       "                                                                                         max_features=20000),\n",
       "                                                                         'Text'),\n",
       "                                                                        ('num',\n",
       "                                                                         StandardScaler(),\n",
       "                                                                         ['n_words']),\n",
       "                                                                        ('ord',\n",
       "                                                                         OrdinalEncoder(categories=[['neg',\n",
       "                                                                                                     'compound',\n",
       "                                                                                                     'neu',\n",
       "                                                                                                     'pos']]),\n",
       "                                                                         ['sentiment'])])),\n",
       "                                       ('svr', SVR())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'svr__gamma': array([0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008,\n",
       "       0.0009, 0.001 , 0.0011, 0.0012, 0.0013, 0.0014])},\n",
       "             scoring='r2', verbose=1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_pipe = Pipeline(\n",
    "        steps=[\n",
    "            (\"prepro\", preprocessor),\n",
    "            (\"svr\", SVR())\n",
    "        ]\n",
    "    )\n",
    "param_grid = {\n",
    "        'svr__gamma': np.arange(0.0001, 0.0015, 0.0001)\n",
    "    }\n",
    "hyper_parameters_search = GridSearchCV(svr_pipe, param_grid=param_grid, n_jobs=-1, scoring='r2', verbose=1)\n",
    "hyper_parameters_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>2.198422</td>\n",
       "      <td>0.511951</td>\n",
       "      <td>0.532790</td>\n",
       "      <td>0.799778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>28.988741</td>\n",
       "      <td>8.086322</td>\n",
       "      <td>0.469965</td>\n",
       "      <td>0.723018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fit_time  score_time  test_score  train_score\n",
       "Ridge   2.198422    0.511951    0.532790     0.799778\n",
       "SVR    28.988741    8.086322    0.469965     0.723018"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_validate(\n",
    "    hyper_parameters_search.best_estimator_,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    scoring='r2',\n",
    "    return_train_score=True)\n",
    "\n",
    "df = pd.DataFrame(scores)\n",
    "results_df[\"SVR\"] = df.mean()\n",
    "pd.DataFrame(results_df).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tuned our model with hyper-parameter optimization. Specifically, we tuned the Gamma hyperparameter of SVR using sklearn's GridSearchCV. The Gamma hyperparameter controls the complexity of our model. We want to pick the best Gamma so that our model does a decent job in predicting while avoiding over-fitting.\n",
    "\n",
    "Below is our tuned, best performing model based on cross-validation score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model Name | Hyperparameter - Gamma | Mean Fit Time |  Mean Scoring Time | Mean CV Score |\n",
    "|------------|------------------------|---------------|--------------------|---------------|\n",
    "|    SVR     |  0.0007000000000000001 | 43.80s | 11.40s |0.4700 |\n",
    "\n",
    "For a more detailed GridSearchCV result, see [this file](../results/hyper_param_search_result.csv)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Random Forest <a class=\"anchor\" id=\"5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yuzhe\\miniconda3\\envs\\573\\lib\\site-packages\\sklearn\\model_selection\\_search.py:278: UserWarning: The total space of parameters 9 is smaller than n_iter=1000. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=Pipeline(steps=[('prepro',\n",
       "                                              ColumnTransformer(transformers=[('text',\n",
       "                                                                               CountVectorizer(max_df=0.6,\n",
       "                                                                                               max_features=20000),\n",
       "                                                                               'Text'),\n",
       "                                                                              ('num',\n",
       "                                                                               StandardScaler(),\n",
       "                                                                               ['n_words']),\n",
       "                                                                              ('ord',\n",
       "                                                                               OrdinalEncoder(categories=[['neg',\n",
       "                                                                                                           'compound',\n",
       "                                                                                                           'neu',\n",
       "                                                                                                           'pos']]),\n",
       "                                                                               ['sentiment'])])),\n",
       "                                             ('randomforestregressor',\n",
       "                                              RandomForestRegressor(random_state=26))]),\n",
       "                   n_iter=1000, n_jobs=-1,\n",
       "                   param_distributions={'randomforestregressor__max_depth': [20,\n",
       "                                                                             25,\n",
       "                                                                             30],\n",
       "                                        'randomforestregressor__n_estimators': [1,\n",
       "                                                                                10,\n",
       "                                                                                100]},\n",
       "                   scoring='r2')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_pipe = Pipeline(\n",
    "        steps=[\n",
    "            (\"prepro\", preprocessor),\n",
    "            (\"randomforestregressor\", RandomForestRegressor(random_state=26))\n",
    "        ]\n",
    " )\n",
    "param_grid1 = {\n",
    "        'randomforestregressor__max_depth': [int(x) for x in np.linspace(20, 30, num = 3)],\n",
    "        'randomforestregressor__n_estimators': [1, 10, 100]\n",
    "    }\n",
    "hyper_parameters_search = RandomizedSearchCV(rf_pipe, param_distributions=param_grid1, n_jobs=-1, scoring='r2', n_iter=1000)\n",
    "hyper_parameters_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'randomforestregressor__n_estimators': 100,\n",
       " 'randomforestregressor__max_depth': 30}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_parameters_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>2.198422</td>\n",
       "      <td>0.511951</td>\n",
       "      <td>0.532790</td>\n",
       "      <td>0.799778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>28.988741</td>\n",
       "      <td>8.086322</td>\n",
       "      <td>0.469965</td>\n",
       "      <td>0.723018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>287.661862</td>\n",
       "      <td>0.499031</td>\n",
       "      <td>0.359660</td>\n",
       "      <td>0.906179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         fit_time  score_time  test_score  train_score\n",
       "Ridge                    2.198422    0.511951    0.532790     0.799778\n",
       "SVR                     28.988741    8.086322    0.469965     0.723018\n",
       "RandomForestRegressor  287.661862    0.499031    0.359660     0.906179"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_validate(\n",
    "    hyper_parameters_search.best_estimator_,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    scoring='r2',\n",
    "    return_train_score=True)\n",
    "\n",
    "df = pd.DataFrame(scores)\n",
    "results_df[\"RandomForestRegressor\"] = df.mean()\n",
    "pd.DataFrame(results_df).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tuned two major hyperparameters of the `RandomForest` regressor, `max_depth` and `n_estimators`, simultaneously. The results of hyperparameter optimization indicate that increasing both `max_depth` and `n_estimators` of the model improves the performance of the model over the training set continuously, however the validation scores are not improved significantly (changes in the order of  $10^{-4}$ ). According to above results, the model is overfitting with our data as the gap between the train and test scores is large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI. Conclusion <a class=\"anchor\" id=\"6\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, Random Forest is not a suitable model for our project due to low validation score and severe overfitting. Between `Ridge` and `SVR`, `Ridge` has the highest validation score. Both `Ridge` and `SVR` appear to overfit, but the degree to which they overfit is similar. <br> \n",
    "As a result, we choose `Ridge` as our best model among the three. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Scikit-learn: Machine Learning in Python, Pedregosa et al., JMLR 12, pp. 2825-2830, 2011. (https://jmlr.csail.mit.edu/papers/v12/pedregosa11a.html) <a class=\"anchor\" id=\"c3\"></a>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
